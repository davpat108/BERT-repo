{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-947e3a953774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Elmegyek a boltba paradicsomért!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Nem szeretem a szilvát.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'Size'"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opti\n",
    "import csv\n",
    "\n",
    "\n",
    "def wordextractor(sentence, number):\n",
    "    words=sentence.split(\" \")\n",
    "    return words[number]\n",
    "\n",
    "def casetonumber(case):\n",
    "    switch = {\n",
    "        \"Nom\": 1,\n",
    "        \"Acc\": 2,\n",
    "        \"Ins\": 3,\n",
    "        \"Ine\": 4, \n",
    "        \"Sup\": 5,\n",
    "        \"Sub\": 6\n",
    "    }\n",
    "    return switch.get(case, \"Invalid case\")\n",
    "\n",
    "def BERT(sentence, tokenizer, model):\n",
    "    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors = \"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "s=[\"Elmegyek a boltba paradicsomért!\", \"Nem szeiojretem a szilvát.\"]\n",
    "print(BERT(s, tokenizer, model)[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "file1 = open(\"train.tsv\")\n",
    "train_tsv=csv.reader( file1, delimiter=\"\\t\")\n",
    "\n",
    "file2 = open(\"test.tsv\")\n",
    "test_tsv=csv.reader( file2, delimiter=\"\\t\")\n",
    "\n",
    "training_data=[]\n",
    "test_data=[]\n",
    "i=0 \n",
    "for obj in train_tsv:\n",
    "    training_data.append([])\n",
    "    training_data[i].append(obj[0])\n",
    "    training_data[i].append(obj[2])\n",
    "    training_data[i].append(casetonumber(obj[3]))\n",
    "    i=i+1\n",
    "\n",
    "i=0\n",
    "for obj in test_tsv:\n",
    "    test_data.append([])\n",
    "    test_data[i].append(obj[0])\n",
    "    test_data[i].append(obj[2])\n",
    "    test_data[i].append(casetonumber(obj[3]))\n",
    "    i=i+1\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "testloader=torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "file1.close()\n",
    "file2.close()\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fcc512f9e80>\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h = self.input_layer(X)\n",
    "        h = self.relu(h)\n",
    "        out = self.output_layer(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
